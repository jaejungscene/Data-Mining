{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# Word Count in Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Spark 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-qHai2252mI"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspark\n",
        "# !pip install -U -q PyDrive\n",
        "# !apt install openjdk-8-jdk-headless -qq\n",
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh"
      },
      "source": [
        "Google Drive client 권한을 받아 Spark 실습을 위해 사용될 파일을 받기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "outputs": [],
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0orRvrc1-545"
      },
      "outputs": [],
      "source": [
        "# id='1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa'\n",
        "# downloaded = drive.CreateFile({'id': id})\n",
        "# downloaded.GetContentFile('pg100.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3"
      },
      "source": [
        "*pg100.txt* 파일은 셰익스피어의 작품들의 사본들을 가지고 있습니다.\n",
        "\n",
        "Spark를 사용하여 각 영어 letter로 시작하는 단어들의 갯수들을 출력하는 프로그램을 만들어보세요. \b한마디로 각 letter에 대해, (non-unique)한 단어들의 총 갯수들을 세는 것입니다.\n",
        "\n",
        "**대소문자는 무시하세요**, i.e. 단어들 전부 lower case라 생각하시면 됩니다. 또한, 알파벳이 아닌 character로 시작하는 단어들도 무시해도 됩니다. **문서 전체**에 대해 word count를 출력하세요(제목, 저자, 줄거리 포함). 라인 바꿈으로 -으로 연결된 단어들은 두 개의 다른 단어로 counting되어도 됩니다(e.g. \"project\", \"pro-ject\" 는 다른 단어).\n",
        "\n",
        "출력에 대한 오차범위는 5미만으로 나오게 해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xu-e7Ph2_ruG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "import pandas as pd\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-SSxDs9FdJa",
        "outputId": "36424e0f-dcd5-4e94-9636-3c3233d8314d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|letter| count|\n",
            "+------+------+\n",
            "|     a| 76666|\n",
            "|     b| 35712|\n",
            "|     c| 19564|\n",
            "|     d| 20314|\n",
            "|     e| 12056|\n",
            "|     f| 27244|\n",
            "|     g| 14405|\n",
            "|     h| 48531|\n",
            "|     i| 56010|\n",
            "|     j|  1539|\n",
            "|     k|  6314|\n",
            "|     l| 18669|\n",
            "|     m| 42047|\n",
            "|     n| 20434|\n",
            "|     o| 37408|\n",
            "|     p| 16220|\n",
            "|     q|  1428|\n",
            "|     r|  8626|\n",
            "|     s| 48269|\n",
            "|     t|114500|\n",
            "|     u|  7049|\n",
            "|     v|  3442|\n",
            "|     w| 49993|\n",
            "|     x|     1|\n",
            "|     y| 21646|\n",
            "|     z|    33|\n",
            "+------+------+\n",
            "only showing top 26 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documents = sc.textFile('./pg100.txt')\n",
        "\n",
        "counts = documents.flatMap(lambda line: line.split()).filter(lambda word: word.isalpha()) \\\n",
        "                        .map(lambda word: word[0].lower()) \\\n",
        "                        .map(lambda letter: (letter, 1)) \\\n",
        "                        .reduceByKey(lambda n1, n2: n1 + n2)\\\n",
        "                        .sortByKey(lambda letter_cnt:letter_cnt[0])\n",
        "counts.toDF(['letter','count']).show(26)\n",
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
